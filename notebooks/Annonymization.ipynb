{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94d70b7-45b8-4352-ac8c-4e4249d8fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anjana.anonymity import k_anonymity_inner, k_anonymity, l_diversity, t_closeness, alpha_k_anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c49e8b-9c2e-4600-b5b3-fde2532d8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/adult/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e43ad3-01bb-4ba4-aed0-44a23cca034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1221 rows\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path + \"data.csv\")\n",
    "len_data = len(data)\n",
    "\n",
    "# Clean the data\n",
    "data['income'] = data['income'].str.rstrip('.')\n",
    "data.dropna(inplace=True)\n",
    "data.drop(columns=['education-num', 'fnlwgt'], inplace=True)\n",
    "\n",
    "len_clean_data = len(data)\n",
    "print(f\"Dropped {len_data - len_clean_data} rows\")\n",
    "data.to_csv(path + \"clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e0fdb9-6bdc-4c67-9317-5fdc26bc690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchies = {\n",
    "    \"age\": dict(pd.read_csv(\"../hierarchies/age.csv\", header=None)),\n",
    "    \"education\": dict(pd.read_csv(\"../hierarchies/education.csv\", header=None)),\n",
    "    \"marital-status\": dict(pd.read_csv(\"../hierarchies/marital.csv\", header=None)),\n",
    "    \"occupation\": dict(pd.read_csv(\"../hierarchies/occupation.csv\", header=None)),\n",
    "    \"sex\": dict(pd.read_csv(\"../hierarchies/sex.csv\", header=None)),\n",
    "    \"native-country\": dict(pd.read_csv(\"../hierarchies/country.csv\", header=None)),\n",
    "    \"workclass\": dict(pd.read_csv(\"../hierarchies/workclass.csv\", header=None)),\n",
    "    \"relationship\": dict(pd.read_csv(\"../hierarchies/relationship.csv\", header=None)),\n",
    "    \"race\": dict(pd.read_csv(\"../hierarchies/race.csv\", header=None)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f0cbf2-1344-4f47-8fb2-b5460c8bb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check with mina what should be identified as quai identifiers\n",
    "quasi_ident = [\n",
    "    'age',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'workclass', # Makes k decrease a LOT\n",
    "    'relationship', # Makes more sense to drop this altogether. Algorithms generalize it to * but increases k a lot\n",
    "    # 'race'\n",
    "]\n",
    "ident = ['race'] # Making race quasi identifier make k much larger\n",
    "sens_att = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2f49c4-5b5e-4622-b41b-2773663c5ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            :   74,   14,    8,    5,    3,    2,    1\n",
      "education      :   16,    5,    3,    1\n",
      "marital-status :    7,    2,    1\n",
      "occupation     :   15,    3,    1\n",
      "sex            :    2,    1\n",
      "native-country :   42,    7,    1\n",
      "workclass      :    9,    4,    1\n",
      "relationship   :    6,    1\n",
      "race           :    5,    1\n",
      "Order in which features will be generalized:\n",
      "['age', 'native-country', 'education', 'occupation', 'age', 'workclass', 'age', 'marital-status', 'native-country', 'relationship', 'age', 'education', 'race', 'workclass', 'age', 'education', 'occupation', 'age', 'marital-status', 'sex', 'age', 'education', 'marital-status', 'occupation', 'sex', 'native-country', 'workclass', 'relationship', 'race']\n"
     ]
    }
   ],
   "source": [
    "all_counts_and_features = []\n",
    "for feat, items in hierarchies.items():\n",
    "    for item in items.values():\n",
    "        length = len(item.unique())\n",
    "        all_counts_and_features.append((length, feat))\n",
    "sorted_data = sorted(\n",
    "    all_counts_and_features, \n",
    "    key=lambda x: x[0], \n",
    "    reverse=True\n",
    ")\n",
    "ordered_features = [feat for count, feat in sorted_data]\n",
    "\n",
    "for feat, items in hierarchies.items():\n",
    "    lengths = [f\"{len(item.unique()):>4}\" for item in items.values()]\n",
    "    out = \", \".join(lengths)\n",
    "    print(f\"{feat:<15}: {out}\")\n",
    "\n",
    "print(\"Order in which features will be generalized:\")\n",
    "print(ordered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda838fc-3bf9-4ab5-9cc8-74e9f5a68362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max rows that can be suppressed: 9524\n",
      "Rows suppressed                : 8580\n",
      "% of allowed rows suppressed   : 90.1%\n",
      "Generalization level           : 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 2,\n",
       " 'education': 1,\n",
       " 'marital-status': 0,\n",
       " 'occupation': 1,\n",
       " 'sex': 0,\n",
       " 'native-country': 1,\n",
       " 'workclass': 1,\n",
       " 'relationship': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with mina if this k is representative of used k in litterature\n",
    "k = 10\n",
    "supp_level = 20 # Select the suppression limit allowed\n",
    "anon_df, supp_n, hiear = k_anonymity_inner(\n",
    "    data, ident, quasi_ident, k, supp_level, hierarchies\n",
    ")\n",
    "max_supp_n = int(round(len(data) * supp_level / 100, 0))\n",
    "print(f\"Max rows that can be suppressed: {max_supp_n}\")\n",
    "print(f\"Rows suppressed                : {supp_n}\")\n",
    "print(f\"% of allowed rows suppressed   : {round(supp_n / max_supp_n * 100, 1)}%\")\n",
    "print(f\"Generalization level           : {sum(hiear.values())}\")\n",
    "hiear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e93cfebe-5366-4146-b77f-a749ba19cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0.1 ----\n",
      "---- 0.2 ----\n",
      "---- 0.3 ----\n",
      "---- 0.4 ----\n",
      "---- 0.5 ----\n",
      "---- 0.6 ----\n",
      "---- 0.7 ----\n",
      "---- 0.8 ----\n",
      "The data verifies t-closeness with t=0.7388386567967009\n",
      "---- 0.9 ----\n",
      "The data verifies t-closeness with t=0.7388386567967009\n",
      "---- 1.0 ----\n",
      "The data verifies t-closeness with t=0.7388386567967009\n"
     ]
    }
   ],
   "source": [
    "for t in np.linspace(0.1,1.0,10):\n",
    "    t = round(t, 1) \n",
    "    print(f\"---- {t} ----\")\n",
    "    if(df.empty):\n",
    "        print(\"Skipping\") \n",
    "        continue\n",
    "    t_closeness(\n",
    "        data, ident, quasi_ident,sens_att, k, t, supp_level, hierarchies\n",
    "    ).to_csv(f\"../data/t_closeness/{t}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0777e74c-37f0-4fc1-8f74-f98a7779d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0.1 ----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m alpha = \u001b[38;5;28mround\u001b[39m(alpha, \u001b[32m1\u001b[39m) \n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43malpha_k_anonymity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquasi_ident\u001b[49m\u001b[43m,\u001b[49m\u001b[43msens_att\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupp_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhierarchies\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(df.empty):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkipping\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m<@beartype(anjana.anonymity._k_anonymity.alpha_k_anonymity) at 0x7aedc21dbe20>:172\u001b[39m, in \u001b[36malpha_k_anonymity\u001b[39m\u001b[34m(__beartype_object_614640000, __beartype_get_violation, __beartype_conf, __beartype_object_135161581258624, __beartype_object_135161580181056, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/anjana/anonymity/_k_anonymity.py:112\u001b[39m, in \u001b[36malpha_k_anonymity\u001b[39m\u001b[34m(data, ident, quasi_ident, sens_att, k, alpha, supp_level, hierarchies)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;129m@beartype\u001b[39m()\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34malpha_k_anonymity\u001b[39m(\n\u001b[32m     70\u001b[39m     data: pd.DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m     hierarchies: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m     78\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Anonymize a dataset using (alpha,k)-anonymity.\u001b[39;00m\n\u001b[32m     80\u001b[39m \n\u001b[32m     81\u001b[39m \u001b[33;03m    :param data: data under study.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m \u001b[33;03m    :rtype: pandas dataframe\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     data_kanon, supp_records, gen_level = \u001b[43mk_anonymity_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquasi_ident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupp_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhierarchies\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m alpha > \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m alpha < \u001b[32m0\u001b[39m:\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    118\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid value of alpha for (alpha,k)-anonymity \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/anjana/anonymity/_k_anonymity.py:263\u001b[39m, in \u001b[36mk_anonymity_inner\u001b[39m\u001b[34m(data, ident, quasi_ident, k, supp_level, hierarchies)\u001b[39m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data, supp_records, gen_level\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     equiv_class = \u001b[43mpycanon\u001b[49m\u001b[43m.\u001b[49m\u001b[43manonymity\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43maux_anonymity\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_equiv_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquasi_ident\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m     len_ec = [\u001b[38;5;28mlen\u001b[39m(ec) \u001b[38;5;28;01mfor\u001b[39;00m ec \u001b[38;5;129;01min\u001b[39;00m equiv_class]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k <= \u001b[38;5;28mmax\u001b[39m(len_ec):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pycanon/anonymity/utils/aux_anonymity.py:49\u001b[39m, in \u001b[36mget_equiv_class\u001b[39m\u001b[34m(data, quasi_ident)\u001b[39m\n\u001b[32m     47\u001b[39m df_grouped = data.groupby(by=quasi_ident)\n\u001b[32m     48\u001b[39m equiv_class = []\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ec \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_grouped\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m.values():\n\u001b[32m     50\u001b[39m     equiv_class.append(np.array(ec.tolist()))\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m equiv_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:851\u001b[39m, in \u001b[36mBaseGroupBy.groups\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgroups\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[Hashable, np.ndarray]:\n\u001b[32m    808\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    809\u001b[39m \u001b[33;03m    Dict {group name -> group labels}.\u001b[39;00m\n\u001b[32m    810\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    849\u001b[39m \u001b[33;03m    {Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}\u001b[39;00m\n\u001b[32m    850\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mproperties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pandas/core/groupby/ops.py:727\u001b[39m, in \u001b[36mBaseGrouper.groups\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    725\u001b[39m         to_groupby.append(gv.groupings[\u001b[32m0\u001b[39m].grouping_vector)\n\u001b[32m    726\u001b[39m index = MultiIndex.from_arrays(to_groupby)\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6450\u001b[39m, in \u001b[36mIndex.groupby\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m   6447\u001b[39m result = values._reverse_indexer()\n\u001b[32m   6449\u001b[39m \u001b[38;5;66;03m# map to the label\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6450\u001b[39m result = {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result.items()}\n\u001b[32m   6452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PrettyDict(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:1174\u001b[39m, in \u001b[36mIndex.take\u001b[39m\u001b[34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;66;03m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n\u001b[32m   1171\u001b[39m     taken = values.take(\n\u001b[32m   1172\u001b[39m         indices, allow_fill=allow_fill, fill_value=\u001b[38;5;28mself\u001b[39m._na_value\n\u001b[32m   1173\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_constructor\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_simple_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:649\u001b[39m, in \u001b[36mIndex._simple_new\u001b[39m\u001b[34m(cls, values, name, refs)\u001b[39m\n\u001b[32m    634\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(dtype)\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# NOTE for new Index creation:\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# - _simple_new: It returns new Index with the same type as the caller.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m \n\u001b[32m    647\u001b[39m \u001b[38;5;66;03m# See each method's docstring.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_simple_new\u001b[39m(\n\u001b[32m    651\u001b[39m     \u001b[38;5;28mcls\u001b[39m, values: ArrayLike, name: Hashable | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, refs=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    652\u001b[39m ) -> Self:\n\u001b[32m    653\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    654\u001b[39m \u001b[33;03m    We require that we have a dtype compat for the values. If we are passed\u001b[39;00m\n\u001b[32m    655\u001b[39m \u001b[33;03m    a non-dtype compat, then coerce using the constructor.\u001b[39;00m\n\u001b[32m    656\u001b[39m \n\u001b[32m    657\u001b[39m \u001b[33;03m    Must be careful not to recurse.\u001b[39;00m\n\u001b[32m    658\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mcls\u001b[39m._data_cls), \u001b[38;5;28mtype\u001b[39m(values)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for alpha in np.linspace(0.1,1.0,10):\n",
    "    alpha = round(alpha, 1) \n",
    "    print(f\"---- {alpha} ----\")\n",
    "    df = alpha_k_anonymity(\n",
    "        data, ident, quasi_ident,sens_att, k, alpha, supp_level, hierarchies\n",
    "    )\n",
    "    if(df.empty):\n",
    "        print(\"Skipping\") \n",
    "        continue\n",
    "    df.to_csv(f\"../data/alpha_k_anonymity/{alpha}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ae27e4-e89c-49bb-8dda-5463aed0aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 1 ----\n",
      "The data verifies l-diversity with l=1\n",
      "---- 2 ----\n",
      "---- 3 ----\n",
      "l-diversity cannot be achieved for l=3\n",
      "Skipping\n",
      "---- 4 ----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,\u001b[32m11\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = \u001b[43ml_diversity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquasi_ident\u001b[49m\u001b[43m,\u001b[49m\u001b[43msens_att\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupp_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhierarchies\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m(df.empty):\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkipping\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m<@beartype(anjana.anonymity._l_diversity.l_diversity) at 0x71e159adf420>:169\u001b[39m, in \u001b[36ml_diversity\u001b[39m\u001b[34m(__beartype_object_1088400592, __beartype_get_violation, __beartype_conf, __beartype_object_125214192024256, __beartype_object_125212687007680, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/anjana/anonymity/_l_diversity.py:71\u001b[39m, in \u001b[36ml_diversity\u001b[39m\u001b[34m(data, ident, quasi_ident, sens_att, k, l_div, supp_level, hierarchies)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;129m@beartype\u001b[39m()\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34ml_diversity\u001b[39m(\n\u001b[32m     29\u001b[39m     data: pd.DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     hierarchies: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m     37\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Anonymize a dataset using l-diversity.\u001b[39;00m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[33;03m    :param data: data under study.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m \u001b[33;03m    :rtype: pandas dataframe\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     data_anon, _ = \u001b[43m_l_diversity_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquasi_ident\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msens_att\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_div\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupp_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhierarchies\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_anon\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/anjana/anonymity/_l_diversity.py:393\u001b[39m, in \u001b[36m_l_diversity_inner\u001b[39m\u001b[34m(data, ident, quasi_ident, sens_att, k, l_div, supp_level, hierarchies)\u001b[39m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ml-diversity cannot be achieved for l=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml_div\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(), supp_records_k\n\u001b[32m    392\u001b[39m qi_gen = quasi_ident_gen[\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     np.argmax([\u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_kanon\u001b[49m\u001b[43m[\u001b[49m\u001b[43mqi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m qi \u001b[38;5;129;01min\u001b[39;00m quasi_ident_gen])\n\u001b[32m    394\u001b[39m ]\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    397\u001b[39m     generalization_qi = utils.apply_hierarchy(\n\u001b[32m    398\u001b[39m         data_kanon[qi_gen].values, hierarchies[qi_gen], gen_level[qi_gen] + \u001b[32m1\u001b[39m\n\u001b[32m    399\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:289\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    287\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bachelor/Masking-Effects-on-XAI-Techniques/.venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:356\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[39m\n\u001b[32m    354\u001b[39m     aux = ar[perm]\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m     aux = ar\n\u001b[32m    358\u001b[39m mask = np.empty(aux.shape, dtype=np.bool)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for l in range(1,11):\n",
    "    print(f\"---- {l} ----\")\n",
    "    df = l_diversity(\n",
    "        data, ident, quasi_ident,sens_att, k, l, supp_level, hierarchies\n",
    "    )\n",
    "    if(df.empty):\n",
    "        print(\"Skipping\") \n",
    "        continue\n",
    "    df.to_csv(f\"../data/l_diversity/{l}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
